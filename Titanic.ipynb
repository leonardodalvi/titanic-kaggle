{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESAFIO DO TITANIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proposta do desafio é prever quais passageiros sobreviveram ao naufrágio do Titanic, a partir de um conjunto de dados dos passageiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa bibliotecas gerais\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# importa bibliotecas de preparação dos dados\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importa bibliotecas de visualização dos dados\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os dados\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarda PassengerId para fácil acesso\n",
    "\n",
    "PassengerId = test['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informações gerais sobre o conjunto de dados de treino\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra as cinco primeiras linhas do conjunto de dados de treino\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra as cinco últimas linhas do conjunto de dados\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visão geral da distribuição estatística dos dados de treino\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma dos dados numéricos de treino\n",
    "\n",
    "train.hist(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma de idade dos passageiros do conjunto de dados de treino\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "fig = sns.distplot(train['Age'], color=\"darkgreen\")\n",
    "fig.set_xlabel(\"Idade\",size=15)\n",
    "fig.set_ylabel(\"Densidade dos Passageiros\",size=15)\n",
    "plt.title('Distribuição de Idade dos Passageiros',size = 20)\n",
    "plt.show()\n",
    "\n",
    "# média de idade dos passageiros do conjunto de dados de treino\n",
    "\n",
    "print('Média de idade dos passageiros: ',train['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma de tarifas dos passageiros do conjunto de dados de treino\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "fig = sns.distplot(train['Fare'], color=\"darkred\")\n",
    "fig.set_xlabel(\"Tarifa\",size=15)\n",
    "fig.set_ylabel(\"Densidade dos Passageiros\",size=15)\n",
    "plt.title('Distribuição de Tarifas dos Passageiros',size = 20)\n",
    "plt.show()\n",
    "\n",
    "# média de tarifa dos passageiros do conjunto de dados de treino\n",
    "\n",
    "print('Média de tarifa dos passageiros: ',train['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota gráficos para Survived x Sex, Pclass e Embarked\n",
    "\n",
    "fig, (axis1, axis2, axis3) = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "sns.barplot(x='Sex', y='Survived', data=train, ax=axis1)\n",
    "sns.barplot(x='Pclass', y='Survived', data=train, ax=axis2)\n",
    "sns.barplot(x='Embarked', y='Survived', data=train, ax=axis3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma para ver influência da idade na probabilidade de sobrevivência\n",
    "\n",
    "age_survived = sns.FacetGrid(train, col='Survived')\n",
    "age_survived.map(sns.distplot, 'Age');\n",
    "#age_survived.map(sns.displot, 'Age', kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota uma scatter matrix\n",
    "\n",
    "columns = ['Parch', 'SibSp', 'Age', 'Pclass']\n",
    "pd.plotting.scatter_matrix(train[columns], figsize=(15,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define função para detectar dados outliers\n",
    "# retorna lista com os registros outliers de acordo com o método de Tukey\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # itera sobre as colunas\n",
    "    for col in features:\n",
    "        # 1o quartil (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3o quartil (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # intervalo interquartil (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # cria lista de índices de outliers por coluna\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # insere o outlier da coluna a uma lista de outliers\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # seleciona linhas contendo mais de 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detecta outliers de Age, SibSp, Parch e Fare\n",
    "outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n",
    "\n",
    "# mostra as linhas com valores outliers\n",
    "train.loc[outliers_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota heatmap de correlação entre dados númericos\n",
    "\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Correlações entre variáveis', y=1.05, size=15)\n",
    "sns.heatmap(train.corr(), cmap='coolwarm', fmt='.2f', linewidths=0.1, vmax=1.0, square=True, linecolor='white', annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatena dados em um único dataframe e preenche campos vazios e nulos com NaN\n",
    "df_total = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n",
    "df_total = df_total.fillna(np.nan)\n",
    "\n",
    "# verifica quantidade de valores nulos no conjunto inteiro\n",
    "df_total.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria lista para o total de dados\n",
    "\n",
    "data = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria coluna que informa se um passageiro possuía uma cabine\n",
    "\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria coluna que informa o tamanho da família do passageiro (contando com ele, combinando SibSp e Parch)\n",
    "\n",
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove todos os valores NULL na coluna Embarked, preenchendo com o valor modal\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove todos os valores NULL na coluna Fare, preenchendo com o valor mediano\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria coluna com categorias (classes) de tarifas (Fare), dividindo os dados de treino em quartis\n",
    "\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove todos os valores NULL na coluna Age, preenchendo com valores aleatórios dentro do desvio-padrão considerando a média de idades\n",
    "\n",
    "for dataset in data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria coluna com categorias (classes) de idades (Age), dividindo os dados de treino em quintis\n",
    "\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define função para extrair o título dos nomes dos passageiros\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    \n",
    "    # se existir o título, extrai e retorna\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria coluna contendo o título dos nomes dos passageiros\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversão dos dados \n",
    "\n",
    "for dataset in data:\n",
    "    \n",
    "    # agrupa títulos não comuns em um único grupo \"Rare\"\n",
    "    \n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # converte Sex em 0 ou 1\n",
    "    \n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # converte títulos em 1, 2, 3, 4 ou 5\n",
    "    \n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # converte Embarked em 0, 1 ou 2\n",
    "    \n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # agrupa valores de Fare e converte em 0, 1, 2 ou 3\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # agrupa valores de Age e converte em 0, 1, 2, 3 ou 4\n",
    "    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4;\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclui colunas desnecessárias\n",
    "\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota heatmap de correlação entre dados númericos\n",
    "\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Correlações entre variáveis', y=1.05, size=15)\n",
    "sns.heatmap(train.corr(), cmap='coolwarm', fmt='.2f', linewidths=0.1, vmax=1.0, square=True, linecolor='white', annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retorna ndarray (array multidimensional) da coluna Survived do conjunto de treino\n",
    "\n",
    "y_train = train['Survived'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclui a coluna Survived do dataset de treino\n",
    "\n",
    "train.drop(['Survived'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria arrays com os dados de teste e com os dados de treino\n",
    "\n",
    "x_train = train.values\n",
    "x_test = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Regressão Logística\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# cria modelo de Regressão Logística\n",
    "\n",
    "lr_model = LogisticRegression(solver='liblinear')\n",
    "lr_model.fit(x_train, y_train)\n",
    "lr_predictions = lr_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo de Regressão Logística\n",
    "\n",
    "acc_logReg = round(lr_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo de Regressão Logística: {}\".format(acc_logReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Árvore de Decisão\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# cria modelo de Árvore de Decisão\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth=3)\n",
    "tree_model.fit(x_train, y_train)\n",
    "tree_predictions = tree_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo de Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo de Árvore de Decisão\n",
    "\n",
    "acc_tree = round(tree_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo de Regressão Logística: {}\".format(acc_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Bagging\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# cria modelo Bagging\n",
    "\n",
    "bg_model = BaggingClassifier()\n",
    "bg_model.fit(x_train, y_train)\n",
    "bg_predictions = bg_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo Bagging\n",
    "\n",
    "acc_bg = round(bg_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo Bagging: {}\".format(acc_bg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# cria modelo de Random Forest\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train, y_train)\n",
    "rf_predictions = rf_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo de Random Forest\n",
    "\n",
    "acc_rf = round(rf_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo de Random Forest: {}\".format(acc_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# cria modelo de AdaBoost\n",
    "\n",
    "bst_model = AdaBoostClassifier(n_estimators=100)\n",
    "bst_model.fit(x_train, y_train)\n",
    "bst_predictions = bst_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo de AdaBoost\n",
    "\n",
    "acc_bst = round(bst_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo de AdaBoost: {}\".format(acc_bst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# cria modelo de Gradient Boosting\n",
    "\n",
    "gbst_model = GradientBoostingClassifier(n_estimators=100)\n",
    "gbst_model.fit(x_train, y_train)\n",
    "gbst_predictions = gbst_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo de Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo de Gradient Boosting\n",
    "\n",
    "acc_gbst = round(gbst_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo de Gradient Boosting: {}\".format(acc_gbst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de XGB\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# cria modelo XGB\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo XGB\n",
    "\n",
    "acc_xgb = round(xgb_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo XGB: {}\".format(acc_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# cria modelo SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(x_train, y_train)\n",
    "svc_predictions = svc_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo SVC\n",
    "\n",
    "acc_svc = round(svc_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo SVC: {}\".format(acc_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de LinearSVC\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# cria modelo Linear SVC\n",
    "\n",
    "lsvc_model = LinearSVC()\n",
    "lsvc_model.fit(x_train, y_train)\n",
    "lsvc_predictions = lsvc_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo Linear SVC\n",
    "\n",
    "acc_lsvc = round(lsvc_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo Linear SVC: {}\".format(acc_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# cria modelo KNN\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train, y_train)\n",
    "knn_predictions = knn_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo KNN\n",
    "\n",
    "acc_knn = round(knn_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo KNN: {}\".format(acc_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# cria modelo Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train, y_train)\n",
    "gnb_predictions = gnb_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo Gaussian Naive Bayes\n",
    "\n",
    "acc_gnb = round(gnb_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo Gaussian Naive Bayes: {}\".format(acc_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Perceptron\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# cria modelo Perceptron\n",
    "\n",
    "percept_model = Perceptron()\n",
    "percept_model.fit(x_train, y_train)\n",
    "percept_predictions = percept_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo Perceptron\n",
    "\n",
    "acc_percept = round(percept_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo Perceptron: {}\".format(acc_percept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Stochastic Gradient Descent\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# cria modelo Stochastic Gradient Descent\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "sgd_predictions = sgd_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo Stochastic Gradient Descent\n",
    "\n",
    "acc_sgd = round(sgd_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo Stochastic Gradient Descent: {}\".format(acc_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de Extra Trees Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# cria modelo Extra Trees Classifier\n",
    "\n",
    "etrees_model = ExtraTreesClassifier()\n",
    "etrees_model.fit(x_train, y_train)\n",
    "etrees_predictions = etrees_model.predict(x_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do modelo Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a acurácia do modelo Extra Trees Classifier\n",
    "\n",
    "acc_etrees = round(etrees_model.score(x_train, y_train) * 100, 2)\n",
    "print(\"Acurácia do modelo Extra Trees Classifier: {}\".format(acc_etrees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação do melhor modelo de Machine Learning para o caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista acurácia dos modelos em sua configuração padrão, em ordem decrescente\n",
    "\n",
    "models = pd.DataFrame({\n",
    "    'Modelo': ['Regressão Logística (Logistic Regression)', 'Árvore de Decisão (Decision Tree)',\n",
    "              'Bagging', 'Random Forest', 'AdaBoost', 'Gradient Boosting',\n",
    "              'XGB', 'SVC', 'Linear SVC', 'KNN', 'Gaussian Naive Bayes', 'Perceptron', 'Stochastic Gradient Decent',\n",
    "              'Extra Trees'],\n",
    "    'Score': [acc_logReg, acc_tree,\n",
    "              acc_bg, acc_rf, acc_bst, acc_gbst,\n",
    "              acc_xgb, acc_svc, acc_lsvc, acc_knn, acc_gnb, acc_percept, acc_sgd, acc_etrees]})\n",
    "\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testa diversos hiperparâmetros para encontrar o que pode ser mais eficiente no modelo selecionado\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "model_params = {\n",
    "    # amostra aleatória de 4 a 200 estimators\n",
    "    'n_estimators': randint(4,200),\n",
    "    # max_features normalmente distribuída, com média .25, desvio-padrão 0.1, limitado entre 0 e 1\n",
    "    'max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "    # distribuição uniforme de 0.01 a 0.2 (0.01 + 0.199)\n",
    "    'min_samples_split': uniform(0.01, 0.199)\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier() # incluir aqui o modelo para o teste\n",
    "\n",
    "# configura a busca aleatória de metaestimadores\n",
    "# isto irá treinar 100 modelos através de 5 dobras de cross validation (500 modelos no total)\n",
    "clf = RandomizedSearchCV(rf_model, model_params, n_iter=100, cv=5, random_state=1)\n",
    "\n",
    "# treina os modelos para encontrar o melhor modelo em cada 100 candidatos\n",
    "model = clf.fit(x_train, y_train)\n",
    "\n",
    "# imprime o conjunto vencedor de hiperparâmetros\n",
    "from pprint import pprint\n",
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliações Adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria matriz de confusão\n",
    "\n",
    "# importa bibliotecas de Cross Validation e Confusion Matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# a primeira linha da matriz é sobre as predições dos não sobreviventes:\n",
    "# em [0,0] temos passageiros que foram classificados corretamente como não sobreviventes (chamados de verdadeiros negativos)\n",
    "# em [0,1] temos passageiros que foram erroneamente classificados como não sobreviventes (falsos negativos)\n",
    "\n",
    "# a segunda linha da matriz é sobre as previsões dos sobreviventes:\n",
    "# em [1,0] temos passageiros classificados erroneamente como sobreviventes (falsos positivos)\n",
    "# em [1,1] temos passageiros corretamente classificados como sobreviventes (positivos verdadeiros)\n",
    "\n",
    "predictions = cross_val_predict(rf_model, x_train, y_train, cv=3)\n",
    "confusion_matrix(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mede a precisão e a recuperação do modelo\n",
    "\n",
    "# importa bibliotecas de Precision Score e Recall Score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Precisão (Precision):\", precision_score(y_train, predictions))\n",
    "print(\"Recuperação (Recall):\",recall_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa bibliotecas de curva de Precision e Recall\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Obtendo as probabilidades de nossas previsões\n",
    "\n",
    "y_scores = rf_model.predict_proba(x_train)\n",
    "y_scores = y_scores[:,1]\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_train, y_scores)\n",
    "\n",
    "# plota gráfico de precisão e recuperação\n",
    "\n",
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"Precisão (precision)\", linewidth=5)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"Recuperação (recall)\", linewidth=5)\n",
    "    plt.xlabel(\"Limite\", fontsize=19)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(17, 9))\n",
    "plot_precision_and_recall(precision, recall, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota gráfico Recall x Precision\n",
    "\n",
    "def plot_precision_vs_recall(precision, recall):\n",
    "    plt.plot(recall, precision, \"g--\", linewidth=2.5)\n",
    "    plt.ylabel(\"Recuperação (Recall)\", fontsize=19)\n",
    "    plt.xlabel(\"Precisão (Precision)\", fontsize=19)\n",
    "    plt.axis([0, 1.5, 0, 1.5])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_precision_vs_recall(precision, recall)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa biblioteca de curva ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# calcular taxa positiva verdadeira e taxa de falsos positivos\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, y_scores)\n",
    "\n",
    "# plotando a Curva ROC AUC\n",
    "\n",
    "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
    "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Taxa de Falsos Positivos', fontsize=16)\n",
    "    plt.ylabel('Taxa de Verdaeiros Positivos', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mede a ROC AUC\n",
    "\n",
    "# importa biblioteca de ROC AUC Score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# cria a medida ROC AUC\n",
    "\n",
    "r_a_score = roc_auc_score(y_train, y_scores)\n",
    "\n",
    "print(\"ROC-AUC Score:\", r_a_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão de um cenário específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevê um cenário específico\n",
    "# sobrevive? => 1 = Sim; 0 = Não\n",
    "\n",
    "# array = Pclass, Sex, Age, Parch, Fare, Embarked, Has_Cabin, FamilySize, Title\n",
    "\n",
    "# Pclass =>      1a Classe = 1; 2a Classe = 2; 3a Classe = 3\n",
    "# Sex =>         Masculino = 1; Feminino = 0\n",
    "# Age =>         <= 16 = 0; > 16 <= 32 = 1; > 32 <= 48 = 2; > 48 <= 64 = 3; > 64 = 4\n",
    "# Parch =>       Quantidade de pais e/ou filhos\n",
    "# Fare =>        <= 7.91 = 0; > 7.91 <= 14.454 = 1; > 14.454 <= 31 = 2; > 31 = 3\n",
    "# Embarked =>    Southampton = 0; Cherbourg-Octeville = 1; Queenstown = 2\n",
    "# Has_Cabin =>   Possui cabine = 1; Não possui cabine = 0\n",
    "# FamilySize =>  Tamanho do grupo familiar, contando com o passageiro\n",
    "# Title =>       Mr. = 1; Miss = 2; Mrs. = 3, Master = 4, Outros = 5\n",
    "\n",
    "rose = np.array([2,0,1,0,1,0,1,2,2]).reshape(1, -1)\n",
    "jack =  np.array([2,1,1,0,1,0,1,2,1]).reshape(1, -1)\n",
    "\n",
    "print(\"Rose sobrevive?\\t{}\".format(rf_model.predict(rose)[0]))\n",
    "print(\"Jack sobrevive?\\t{}\".format(rf_model.predict(jack)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando arquivo para envio ao Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId, 'Survived': rf_predictions })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando arquivo csv para envio\n",
    "StackingSubmission.to_csv(\"rf_submission.csv\", index=False)\n",
    "\n",
    "StackingSubmission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
